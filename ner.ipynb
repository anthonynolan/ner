{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sufficient-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import bigrams\n",
    "import nltk\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "_ = nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-white",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oct.</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  pos\n",
       "0      an   DT\n",
       "1    Oct.  NNP\n",
       "2      19   CD\n",
       "3  review   NN\n",
       "4      of   IN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/WSJ_02-21.pos', sep='\\t', header=0, names=['word', 'pos'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "permanent-fusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>economy</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temperature</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  pos\n",
       "0      economy   NN\n",
       "1           's  POS\n",
       "2  temperature   NN\n",
       "3         will   MD\n",
       "4           be   VB"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/WSJ_24.pos', sep='\\t', header=0, names=['word', 'pos'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "focal-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32852, 950027)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-samba",
   "metadata": {},
   "source": [
    "## First approach is to find the most common tag for a word and just use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "national-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 44389 tuples in the dict\n",
      "an DT\n",
      "Oct. NNP\n",
      "19 CD\n",
      "review VBP\n",
      "of RP\n"
     ]
    }
   ],
   "source": [
    "# for each word get the most popular tuple\n",
    "winners = {}\n",
    "for row in Counter(list(train.itertuples(index=False, name=None))):\n",
    "    if row[0] not in winners:\n",
    "        winners[row[0]] = row[1]\n",
    "    elif winners[row[0]]< row[1]:\n",
    "        winners[row[0]] = row[1]\n",
    "        \n",
    "print(f'There are {len(winners)} tuples in the dict')\n",
    "\n",
    "for key in list(winners.keys())[:5]:\n",
    "    print(key, winners[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sweet-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/dicts/most_common_tag_for_word.json', 'wt') as f:\n",
    "    f.write(json.dumps(winners))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "anonymous-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DT'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners['an']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-table",
   "metadata": {},
   "source": [
    "### Make our predictions on the test set and calculate our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dressed-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NN', 'VBZ', 'NN', 'VB', 'VBP', 'VBN', 'IN', 'JJ', 'NN', 'VBZ', 'RB', 'NN', ',', 'RP', 'NNS', 'RP', 'VBP', ',', 'NN', ',']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5858090831608426"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "unknown = '<UNK>'\n",
    "for row in list(test.itertuples(index=False, name=None)):\n",
    "    if row[0] in winners:\n",
    "        predictions.append(winners[row[0]])\n",
    "    else:\n",
    "        predictions.append(unknown)\n",
    "print(predictions[:20])\n",
    "\n",
    "results = pd.DataFrame({'ground_truth': test['pos'].to_list(), 'prediction': predictions})\n",
    "np.mean(results['ground_truth']==results['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-visibility",
   "metadata": {},
   "source": [
    "## Next try bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "obvious-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the bigrams to find most common pairing of first tuple in key and first element of second tuple\n",
    "bigram_counter = Counter(list(bigrams(train.itertuples(index=False, name=None))))\n",
    "winners = {}\n",
    "for row in bigram_counter:\n",
    "    key = row[0], row[1][0]\n",
    "    if key not in winners:\n",
    "        winners[key] = bigram_counter[row]\n",
    "    elif winners[key]> bigram_counter[row]:\n",
    "        winners[key] = bigram_counter[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "packed-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POS', '<UNK>', '<UNK>', 'VB', 'VBN', 'IN', 'JJ', '<UNK>', '<UNK>', 'DT', 'NN', ',', 'IN', '<UNK>', 'IN', 'NN', ',', 'NN', ',', 'NN']\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "unknown = '<UNK>'\n",
    "for row in list(bigrams(test.itertuples(index=False, name=None))):\n",
    "    key = row[0], row[1][0]\n",
    "    if key in winners:\n",
    "        predictions.append(row[1][1])\n",
    "    else:\n",
    "        predictions.append(unknown)\n",
    "print(predictions[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "transparent-court",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32851, 32852)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that because we are using bigrams there is one less prediction than elements in the test set.\n",
    "# Indexing from [1:] in the DataFrame takes care of that\n",
    "len(predictions), len(test['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "framed-celebration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000700130894036"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'ground_truth': test['pos'].to_list()[1:], 'prediction': predictions})\n",
    "np.mean(results['ground_truth']==results['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-meter",
   "metadata": {},
   "source": [
    "## Next try the NLTK library's built in tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abroad-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above bigram method uses maximum liklihood of tag given word and previous tag,word pair. \n",
    "# Let's try the model just using predict tag given previous tag\n",
    "nltk_tags = nltk.pos_tag(test['word'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "surrounded-divorce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.961767928893218"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'ground_truth': test['pos'].to_list(), 'prediction': [tag[1] for tag in nltk_tags]})\n",
    "np.mean(results['ground_truth']==results['prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
